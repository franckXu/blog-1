<!DOCTYPE html><!--[if lt IE 7]>      <html xmlns="http://www.w3.org/1999/xhtml"
    xmlns:og="http://ogp.me/ns#"
    xmlns:fb="https://www.facebook.com/2008/fbml" class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]-->
<!--[if IE 7]>         <html xmlns="http://www.w3.org/1999/xhtml"
    xmlns:og="http://ogp.me/ns#"
    xmlns:fb="https://www.facebook.com/2008/fbml" class="no-js lt-ie9 lt-ie8"> <![endif]-->
<!--[if IE 8]>         <html xmlns="http://www.w3.org/1999/xhtml"
    xmlns:og="http://ogp.me/ns#"
    xmlns:fb="https://www.facebook.com/2008/fbml" class="no-js lt-ie9"> <![endif]-->
<!--[if gt IE 8]><!--> <html xmlns="http://www.w3.org/1999/xhtml"
    xmlns:og="http://ogp.me/ns#"
    xmlns:fb="https://www.facebook.com/2008/fbml" class="no-js"> <!--<![endif]-->
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
        <meta name="description" content="Vlad's Tech Blog">
        <meta name="viewport" content="width=device-width">
        <title>Machine Learning on Azure - Part 3 &mdash; Blog</title>
            <link rel="stylesheet" href="../../../_static/normalize.css" type="text/css">
            <link rel="stylesheet" href="../../../_static/sphinx.css" type="text/css">
            <link rel="stylesheet" href="../../../_static/main.css" type="text/css">
            <link rel="stylesheet" href="../../../_static/flat.css" type="text/css">
            <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
            <link rel="stylesheet" href="../../../_static/font-awesome.min.css" type="text/css">
        <link rel="shortcut icon" href="../../../_static/tinkerer.ico" /><!-- Load modernizr and JQuery -->
        <script src="../../../_static/vendor/modernizr-2.6.2.min.js"></script>
        <script src="//ajax.googleapis.com/ajax/libs/jquery/1.8.2/jquery.min.js"></script>
        <script>window.jQuery || document.write('<script src="../../../_static/vendor/jquery-1.8.2.min.js"><\/script>')</script>
        <script src="../../../_static/plugins.js"></script>
        <script src="../../../_static/main.js"></script>
        <link rel="search" title="Search" href="../../../search.html" /><link rel="next" title="Machine Learning on Azure - Part 2" href="../17/machine-learning-on-azure-part-2.html" /><link rel="alternate" type="application/rss+xml" title="RSS" href="../../../rss.html" /><script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../../',
        VERSION:     '1.7.2',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        SOURCELINK_SUFFIX: '.txt',
        HAS_SOURCE:  true
      };
    </script><script type="text/javascript" src="../../../_static/underscore.js"></script><script type="text/javascript" src="../../../_static/doctools.js"></script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type="text/javascript" src="../../../_static/google_analytics.js"></script><link rel="stylesheet" href="../../../_static/extra.css" type="text/css" />
<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
</script></head>
    <body role="document">
        <!--[if lt IE 7]>
            <p class="chromeframe">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> or <a href="http://www.google.com/chromeframe/?redirect=true">activate Google Chrome Frame</a> to improve your experience.</p>
        <![endif]-->

      <div id="container"><div class="main-container" role="main"><div class="main wrapper body clearfix"><article><div class="timestamp postmeta">
            <span>September 24, 2021</span>
        </div>
    <div class="section" id="machine-learning-on-azure-part-3">
<h1>Machine Learning on Azure - Part 3</h1>
<p>This is an excerpt from chapter 7 of my book, <a class="reference external" href="https://www.manning.com/books/azure-data-engineering">Data Engineering on Azure</a>,
which deals with machine learning workloads. This is part 3 in a 3 part series.
In this post, we’ll run the model we created in <a class="reference external" href="https://vladris.com/blog/2021/09/10/machine-learning-on-azure-part-1.html">part 1</a>
on the Azure Machine Learning (AML) infrastructure we set up in <a class="reference external" href="https://vladris.com/blog/2021/09/17/machine-learning-on-azure-part-2.html">part 2</a> .</p>
<div class="section" id="running-ml-in-the-cloud">
<h2>Running ML in the cloud</h2>
<p>We use the Python Azure Machine Learning SDK for this, so the first step is to
install it using the Python package manager (pip). First, make sure pip is
up-to-date. (If there is a newer pip version, you should see a message printed
to the console suggesting you upgrade when you run a pip command.) You can
update pip by running <span class="docutils literal"><span class="pre">python</span> <span class="pre">-m</span> <span class="pre">pip</span> <span class="pre">install</span> <span class="pre">--upgrade</span> <span class="pre">pip</span></span> as an
administrator. Once pip is up-to-date, install the Azure Machine Learning SDK
with the command in the following listing:</p>
<div class="highlight-powershell notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">azureml-sdk</span>
</pre></div>
</div>
<p>Let’s now write a Python script to publish our original ML model to the cloud,
with all the required configuration. We’ll call this <span class="docutils literal"><span class="pre">pipeline.py</span></span>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">azureml.core</span> <span class="kn">import</span> <span class="n">Workspace</span><span class="p">,</span> <span class="n">Datastore</span><span class="p">,</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="nn">azureml.core.authentication</span> <span class="kn">import</span> <span class="n">ServicePrincipalAuthentication</span>
<span class="kn">from</span> <span class="nn">azureml.core.compute</span> <span class="kn">import</span> <span class="n">AmlCompute</span>
<span class="kn">from</span> <span class="nn">azureml.core.conda_dependencies</span> <span class="kn">import</span> <span class="n">CondaDependencies</span>
<span class="kn">from</span> <span class="nn">azureml.core.runconfig</span> <span class="kn">import</span> <span class="n">RunConfiguration</span>
<span class="kn">from</span> <span class="nn">azureml.pipeline.core</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">azureml.pipeline.steps.python_script_step</span> <span class="kn">import</span> <span class="n">PythonScriptStep</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="n">tenant_id</span> <span class="o">=</span> <span class="s1">&#39;&lt;your tenant ID&gt;&#39;</span>
<span class="n">subscription_id</span> <span class="o">=</span> <span class="s1">&#39;&lt;your Azure subscription GUID&gt;&#39;</span>
<span class="n">service_principal_id</span> <span class="o">=</span> <span class="s1">&#39;&lt;your service principal ID&gt;&#39;</span>
<span class="n">resource_group</span>  <span class="o">=</span> <span class="s1">&#39;aml-rg&#39;</span>
<span class="n">workspace_name</span>  <span class="o">=</span> <span class="s1">&#39;aml&#39;</span>

<span class="c1"># Auth</span>
<span class="n">auth</span> <span class="o">=</span> <span class="n">ServicePrincipalAuthentication</span><span class="p">(</span>
    <span class="n">tenant_id</span><span class="p">,</span>
    <span class="n">service_principal_id</span><span class="p">,</span>
    <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;SP_PASSWORD&#39;</span><span class="p">))</span>

<span class="c1"># Workspace</span>
<span class="n">workspace</span> <span class="o">=</span> <span class="n">Workspace</span><span class="p">(</span>
    <span class="n">subscription_id</span> <span class="o">=</span> <span class="n">subscription_id</span><span class="p">,</span>
    <span class="n">resource_group</span> <span class="o">=</span> <span class="n">resource_group</span><span class="p">,</span>
    <span class="n">workspace_name</span> <span class="o">=</span> <span class="n">workspace_name</span><span class="p">,</span>
    <span class="n">auth</span><span class="o">=</span><span class="n">auth</span><span class="p">)</span>

<span class="c1"># Datastore</span>
<span class="n">datastore</span> <span class="o">=</span> <span class="n">Datastore</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">workspace</span><span class="p">,</span> <span class="s1">&#39;MLData&#39;</span><span class="p">)</span>

<span class="c1"># Compute target</span>
<span class="n">compute_target</span> <span class="o">=</span> <span class="n">AmlCompute</span><span class="p">(</span><span class="n">workspace</span><span class="p">,</span> <span class="s1">&#39;d1compute&#39;</span><span class="p">)</span>

<span class="c1"># Input</span>
<span class="n">model_input</span> <span class="o">=</span> <span class="n">Dataset</span><span class="o">.</span><span class="n">File</span><span class="o">.</span><span class="n">from_files</span><span class="p">(</span>
    <span class="p">[(</span><span class="n">datastore</span><span class="p">,</span> <span class="s1">&#39;/models/highspenders/input.csv&#39;</span><span class="p">)])</span><span class="o">.</span><span class="n">as_mount</span><span class="p">()</span>

<span class="c1"># Python package configuration</span>
<span class="n">conda_deps</span> <span class="o">=</span> <span class="n">CondaDependencies</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
    <span class="n">pip_packages</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;pandas&#39;</span><span class="p">,</span> <span class="s1">&#39;sklearn&#39;</span><span class="p">,</span> <span class="s1">&#39;azureml-core&#39;</span><span class="p">,</span> <span class="s1">&#39;azureml-dataprep&#39;</span><span class="p">])</span>

<span class="n">run_config</span> <span class="o">=</span> <span class="n">RunConfiguration</span><span class="p">(</span><span class="n">conda_dependencies</span><span class="o">=</span><span class="n">conda_deps</span><span class="p">)</span>

<span class="c1"># Train step</span>
<span class="n">trainStep</span> <span class="o">=</span> <span class="n">PythonScriptStep</span><span class="p">(</span>
    <span class="n">script_name</span><span class="o">=</span><span class="s1">&#39;highspenders.py&#39;</span><span class="p">,</span>
    <span class="n">arguments</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;--input&#39;</span><span class="p">,</span> <span class="n">model_input</span><span class="p">],</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">model_input</span><span class="p">],</span>
    <span class="n">runconfig</span><span class="o">=</span><span class="n">run_config</span><span class="p">,</span>
    <span class="n">compute_target</span><span class="o">=</span><span class="n">compute_target</span><span class="p">)</span>

<span class="c1"># Submit pipeline</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">workspace</span><span class="o">=</span><span class="n">workspace</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="p">[</span><span class="n">trainStep</span><span class="p">])</span>

<span class="n">published_pipeline</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">publish</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s1">&#39;HighSpenders&#39;</span><span class="p">,</span>
    <span class="n">description</span><span class="o">=</span><span class="s1">&#39;High spenders model&#39;</span><span class="p">,</span>
    <span class="n">continue_on_step_failure</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="nb">open</span><span class="p">(</span><span class="s1">&#39;highspenders.id&#39;</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">published_pipeline</span><span class="o">.</span><span class="n">id</span><span class="p">)</span>
</pre></div>
</div>
<p>We’ll break down this script and discuss each part. First, we have the required
imports and the additional parameters we need.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">azureml.core</span> <span class="kn">import</span> <span class="n">Workspace</span><span class="p">,</span> <span class="n">Datastore</span><span class="p">,</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="nn">azureml.core.authentication</span> <span class="kn">import</span> <span class="n">ServicePrincipalAuthentication</span>
<span class="kn">from</span> <span class="nn">azureml.core.compute</span> <span class="kn">import</span> <span class="n">AmlCompute</span>
<span class="kn">from</span> <span class="nn">azureml.core.conda_dependencies</span> <span class="kn">import</span> <span class="n">CondaDependencies</span>
<span class="kn">from</span> <span class="nn">azureml.core.runconfig</span> <span class="kn">import</span> <span class="n">RunConfiguration</span>
<span class="kn">from</span> <span class="nn">azureml.pipeline.core</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">azureml.pipeline.steps.python_script_step</span> <span class="kn">import</span> <span class="n">PythonScriptStep</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="n">tenant_id</span> <span class="o">=</span> <span class="s1">&#39;&lt;your tenant ID&gt;&#39;</span>
<span class="n">subscription_id</span> <span class="o">=</span> <span class="s1">&#39;&lt;your Azure subscription GUID&gt;&#39;</span>
<span class="n">service_principal_id</span> <span class="o">=</span> <span class="s1">&#39;&lt;your service principal ID&gt;&#39;</span>
<span class="n">resource_group</span>  <span class="o">=</span> <span class="s1">&#39;aml-rg&#39;</span>
<span class="n">workspace_name</span>  <span class="o">=</span> <span class="s1">&#39;aml&#39;</span>
</pre></div>
</div>
<p>We import a set of packages from the <span class="docutils literal"><span class="pre">azureml-sdk</span></span>. We need the tenant ID,
subscription ID, and service principal ID we will use to connect to the Azure
Machine Learning service. We created the service principal in <a class="reference external" href="https://vladris.com/blog/2021/09/17/machine-learning-on-azure-part-2.html">part 2</a>.
We stored it in the <span class="docutils literal"><span class="pre">$sp</span></span> variable. In case you closed that PowerShell session
and no longer have the <span class="docutils literal"><span class="pre">$sp</span></span> variable, you can simply rerun the scripts we
covered in part 2 to create a new service principal and grant it the required
permissions.</p>
<p>You can get the service principal ID from <span class="docutils literal"><span class="pre">$sp.appId</span></span> in PowerShell.
Similarly, you can get the tenant ID from <span class="docutils literal"><span class="pre">$sp.tenant</span></span>. The subscription ID
is the GUID of your Azure subscription.</p>
<p>Use these to intialize the <span class="docutils literal"><span class="pre">tenant_id</span></span>, <span class="docutils literal"><span class="pre">subscription_id</span></span>, and
<span class="docutils literal"><span class="pre">service_principal_id</span></span> in the script above.</p>
<p>Next, we connect to the workspace using the service principal and get the data
store (<span class="docutils literal"><span class="pre">MLData</span></span>) and compute target (<span class="docutils literal"><span class="pre">d1compute</span></span>) needed by our model. The
following listing shows the steps.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Auth</span>
<span class="n">auth</span> <span class="o">=</span> <span class="n">ServicePrincipalAuthentication</span><span class="p">(</span>
    <span class="n">tenant_id</span><span class="p">,</span>
    <span class="n">service_principal_id</span><span class="p">,</span>
    <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;SP_PASSWORD&#39;</span><span class="p">))</span>

<span class="c1"># Workspace</span>
<span class="n">workspace</span> <span class="o">=</span> <span class="n">Workspace</span><span class="p">(</span>
    <span class="n">subscription_id</span> <span class="o">=</span> <span class="n">subscription_id</span><span class="p">,</span>
    <span class="n">resource_group</span> <span class="o">=</span> <span class="n">resource_group</span><span class="p">,</span>
    <span class="n">workspace_name</span> <span class="o">=</span> <span class="n">workspace_name</span><span class="p">,</span>
    <span class="n">auth</span><span class="o">=</span><span class="n">auth</span><span class="p">)</span>

<span class="c1"># Datastore</span>
<span class="n">datastore</span> <span class="o">=</span> <span class="n">Datastore</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">workspace</span><span class="p">,</span> <span class="s1">&#39;MLData&#39;</span><span class="p">)</span>

<span class="c1"># Compute target</span>
<span class="n">compute_target</span> <span class="o">=</span> <span class="n">AmlCompute</span><span class="p">(</span><span class="n">workspace</span><span class="p">,</span> <span class="s1">&#39;d1compute&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>Here we define a service principal authentication as <span class="docutils literal"><span class="pre">Auth</span></span> and use the
environment variable <span class="docutils literal"><span class="pre">SP_PASSWORD</span></span> to retrieve the service principal secret.
We set this variable in part 2, after we created the principal.</p>
<p>We connect to the Azure Machine Learning workspace with the given
subscription ID, resource group, name, and auth. We then retrieve the
datastore (<span class="docutils literal"><span class="pre">MLData</span></span>) and compute target (<span class="docutils literal"><span class="pre">d1compute</span></span>) from the workspace.</p>
<p>We need these to set up our deployment: the data store is where we have our
input, while the compute target is where the model trains. The following listing
shows how we can specify the model input.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Input</span>
<span class="n">model_input</span> <span class="o">=</span> <span class="n">Dataset</span><span class="o">.</span><span class="n">File</span><span class="o">.</span><span class="n">from_files</span><span class="p">(</span>
    <span class="p">[(</span><span class="n">datastore</span><span class="p">,</span> <span class="s1">&#39;/models/highspenders/input.csv&#39;</span><span class="p">)])</span><span class="o">.</span><span class="n">as_mount</span><span class="p">()</span>
</pre></div>
</div>
<p>The <span class="docutils literal"><span class="pre">from_files()</span></span> method takes a list of files. Each element of the list is a
tuple consisting of a data store and a path. The <span class="docutils literal"><span class="pre">as_mount()</span></span> method ensures
the file is mounted and made available to the compute that trains the model.</p>
<blockquote>
<div>Azure Machine Learning <em>datasets</em> reference a data source location, along with
a copy of its metadata. This allows models to seamlessly access data during
training.</div></blockquote>
<p>Next, we’ll specify the Python packages required by our model, from which we can
initialize a run configuration. If you remember from part 1, we used <span class="docutils literal"><span class="pre">pandas</span></span>
and <span class="docutils literal"><span class="pre">sklearn</span></span>. We’ll also need the <span class="docutils literal"><span class="pre">azureml-core</span></span> and <span class="docutils literal"><span class="pre">azureml-dataprep</span></span>
packages required by the runtime. The next listing shows how to create the run
configuration.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Python package configuration</span>
<span class="n">conda_deps</span> <span class="o">=</span> <span class="n">CondaDependencies</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
    <span class="n">pip_packages</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;pandas&#39;</span><span class="p">,</span> <span class="s1">&#39;sklearn&#39;</span><span class="p">,</span> <span class="s1">&#39;azureml-core&#39;</span><span class="p">,</span> <span class="s1">&#39;azureml-dataprep&#39;</span><span class="p">])</span>

<span class="n">run_config</span> <span class="o">=</span> <span class="n">RunConfiguration</span><span class="p">(</span><span class="n">conda_dependencies</span><span class="o">=</span><span class="n">conda_deps</span><span class="p">)</span>
</pre></div>
</div>
<p><em>Conda</em> stands for Anaconda, a Python and R open source distribution of common
data science packages. Anaconda simplifies package management and dependencies
and is commonly used in data science projects because it provides a stable
environment for this type of workload. Azure Machine Learning also uses it under
the hood.</p>
<p>Next, let’s create a step for training our model. In our case, this is a
<span class="docutils literal"><span class="pre">PythonScriptStep</span></span>, a step that executes Python code. We’ll provide the name
of the script (from our previous section), the command-line arguments, the
inputs, run configuration, and compute target. The following listing shows the
details.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Train step</span>
<span class="n">trainStep</span> <span class="o">=</span> <span class="n">PythonScriptStep</span><span class="p">(</span>
    <span class="n">script_name</span><span class="o">=</span><span class="s1">&#39;highspenders.py&#39;</span><span class="p">,</span>
    <span class="n">arguments</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;--input&#39;</span><span class="p">,</span> <span class="n">model_input</span><span class="p">],</span>
    <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">model_input</span><span class="p">],</span>
    <span class="n">runconfig</span><span class="o">=</span><span class="n">run_config</span><span class="p">,</span>
    <span class="n">compute_target</span><span class="o">=</span><span class="n">compute_target</span><span class="p">)</span>
</pre></div>
</div>
<p>We specify the script to upload/run with <span class="docutils literal"><span class="pre">script_name</span></span>. This is our
<span class="docutils literal"><span class="pre">highspenders.py</span></span> model we created in part 1. We set the arguments we want
passed to the script as <span class="docutils literal"><span class="pre">arguments</span></span>. Here, <span class="docutils literal"><span class="pre">model_input</span></span> resolves at runtime
to the path where the data is mounted on the node running the script. We set the
inputs, run configuration, and compute target to run on as <span class="docutils literal"><span class="pre">inputs</span></span>,
<span class="docutils literal"><span class="pre">runconfig</span></span>, and <span class="docutils literal"><span class="pre">compute_target</span></span>.</p>
<p>We can chain multiple steps together, but we only need one in our case. One or
more steps form a ML <em>pipeline</em>.</p>
<blockquote>
<div>An Azure Machine Learning <em>pipeline</em> simplifies building ML workflows
including data preparation, training, validation, scoring, and deployment.</div></blockquote>
<p>Pipelines are an important concept in Azure Machine Learning. These capture all
the information needed to run a ML workflow. The following listing shows how we
can create and submit a pipeline to our workspace.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Submit pipeline</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">workspace</span><span class="o">=</span><span class="n">workspace</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="p">[</span><span class="n">trainStep</span><span class="p">])</span>

<span class="n">published_pipeline</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">publish</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s1">&#39;HighSpenders&#39;</span><span class="p">,</span>
    <span class="n">description</span><span class="o">=</span><span class="s1">&#39;High spenders model&#39;</span><span class="p">,</span>
    <span class="n">continue_on_step_failure</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="nb">open</span><span class="p">(</span><span class="s1">&#39;highspenders.id&#39;</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">published_pipeline</span><span class="o">.</span><span class="n">id</span><span class="p">)</span>
</pre></div>
</div>
<p>We create a pipeline with a single step, <span class="docutils literal"><span class="pre">trainStep</span></span> in our workspace. We
publish the pipeline. We’ll save the GUID of the published pipeline into the
<span class="docutils literal"><span class="pre">highspenders.id</span></span> file so we can refer to it later.</p>
<p>This covers the whole <span class="docutils literal"><span class="pre">pipeline.py</span></span> script. Our pipeline automation is almost
complete. But before calling this script to create the pipeline, let’s make one
small addition to our high spender model. While we could do all of the previous
steps without touching our original model code, we add the final step to the
model code itself. Remember that once the model is trained, we save it to disk
as <span class="docutils literal"><span class="pre">outputs/highspender.pkl</span></span>.</p>
<p>For this step, we’ll make one Azure Machine Learning-specific addition: taking
the trained model and storing it in the workspace. Add the lines in the
following listing to the <span class="docutils literal"><span class="pre">highspenders.py</span></span> model we created in part 1 (not to
<span class="docutils literal"><span class="pre">pipeline.py</span></span>, which we just covered).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Register model</span>
<span class="kn">from</span> <span class="nn">azureml.core</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="nn">azureml.core.run</span> <span class="kn">import</span> <span class="n">Run</span>

<span class="n">run</span> <span class="o">=</span> <span class="n">Run</span><span class="o">.</span><span class="n">get_context</span><span class="p">()</span>
<span class="n">workspace</span> <span class="o">=</span> <span class="n">run</span><span class="o">.</span><span class="n">experiment</span><span class="o">.</span><span class="n">workspace</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="o">.</span><span class="n">register</span><span class="p">(</span>
    <span class="n">workspace</span><span class="o">=</span><span class="n">workspace</span><span class="p">,</span>
    <span class="n">model_name</span><span class="o">=</span><span class="s1">&#39;highspender&#39;</span><span class="p">,</span>
    <span class="n">model_path</span><span class="o">=</span><span class="n">model_path</span><span class="p">)</span>
</pre></div>
</div>
<p>Note the call to <span class="docutils literal"><span class="pre">Run.get_context()</span></span> and how we use this to retrieve the
workspace. In <span class="docutils literal"><span class="pre">pipeline.py</span></span>, we provided the subscription ID, resource
group, and workspace name. That is how we can get a workspace from outside Azure
Machine Learning. In this case, though, the code runs in Azure Machine Learning
as part of our pipeline. This gives us additional context that we can use to
retrieve the workspace at runtime. Every run of a pipeline in Azure Machine
Learning is called an <em>experiment</em>.</p>
<blockquote>
<div>Azure Machine Learning <em>experiments</em> represent one execution of a pipeline.
When we rerun a pipeline, we have a new experiment.</div></blockquote>
<p>We are all set! Let’s run the <span class="docutils literal"><span class="pre">pipeline.py</span></span> script to publish our pipeline to
the workspace. The following listing provides the command for this step.</p>
<div class="highlight-powershell notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="n">pipeline</span><span class="p">.</span><span class="n">py</span>
</pre></div>
</div>
<p>The GUID matters! If we rerun the script, it registers another pipeline with the
same name but a different GUID. Azure Machine Learning does not update pipelines
in place. We have the option to disable pipelines so these don’t clutter the
workspace, but not to update those. Let’s kick off the pipeline using Azure CLI
as the next listing shows.</p>
<div class="highlight-powershell notranslate"><div class="highlight"><pre><span></span><span class="nv">$pipelineId</span> <span class="p">=</span> <span class="nb">Get-Content</span> <span class="n">-Path</span> <span class="n">highspenders</span><span class="p">.</span><span class="n">id</span>

<span class="n">az</span> <span class="n">ml</span> <span class="n">run</span> <span class="nb">submit-pipeline</span> <span class="p">`</span>
<span class="p">-</span><span class="n">-pipeline-id</span> <span class="nv">$pipelineId</span> <span class="p">`</span>
<span class="p">-</span><span class="n">-workspace-name</span> <span class="n">aml</span> <span class="p">`</span>
<span class="p">-</span><span class="n">-resource-group</span> <span class="n">aml-rg</span>
</pre></div>
</div>
<p>We read the pipeline ID from the <span class="docutils literal"><span class="pre">highspenders.id</span></span> file produced in the previous
step into the <span class="docutils literal"><span class="pre">$pipelineId</span></span> variable. We then submit a new run.</p>
<p>Check the UI at <a class="reference external" href="https://ml.azure.com">https://ml.azure.com</a>. You should see the pipeline under the
Pipelines section, the run we just kicked off under the Experiments section.
Once the model is trained, you’ll see the model output under the Models section.</p>
</div>
<div class="section" id="azure-machine-learning-recap">
<h2>Azure Machine Learning recap</h2>
<p>After implementing a model in Python, we started with provisioning a workspace,
which is the top-level container for all Azure Machine Learning-related
artifacts. Next, we created a compute target, which specifies the type of
compute our model runs on. We can define as many compute targets as needed;
some models require more resources than others, some require GPUs, etc. Azure
provides many types of VM images suited to all these workloads. A main advantage
of using compute targets in Azure Machine Learning is that compute is
provisioned on demand when we run a pipeline. Once the pipeline finishes,
compute gets deprovisioned. This allows us to scale elastically and only pay for
what we need.</p>
<p>We then attached a data store. Data stores are an abstraction over existing
storage services, and these allow Azure Machine Learning connections to read the
data. The main advantage of using data stores is that these abstract away access
control, so our data scientists don’t need to worry about authenticating against
the storage service.</p>
<p>With the infrastructure in place, we proceeded to set up a pipeline for our
model. A pipeline specifies all the requirements and steps our execution needs
to take. There are many pipelines in Azure: Azure DevOps Pipelines are focused
on DevOps, provisioning resources, and in general, providing automation around
Git; Azure Data Factory pipelines are focused on ETL, data movement, and
orchestration; Azure Machine Learning Pipelines are meant for ML workflows,
where we set up the environment and then execute a set of steps to train,
validate, and publish a model.</p>
<p>Our pipeline included a dataset (our input), a compute target, a set of Python
package dependencies, a run configuration, and a step to run a Python script. We
also enhanced our original model code to publish the model in AML. This takes
the result of our training run and makes it available in the workspace. Then we
published the pipeline to our Azure Machine Learning workspace and submitted a
run, which in Azure Machine Learning is called an experiment.</p>
</div>
<div class="section" id="next-steps">
<h2>Next steps</h2>
<p>We will stop here with the series of article. Grab the book to see how we can
apply DevOps to our ML scenario. In the book, we go over putting both the model
code and <span class="docutils literal"><span class="pre">pipeline.py</span></span> in Git, then deploy updates using Azure DevOps
Pipelines. We also cover orchestrating ML runs with Azure Data Factory, which
includes getting the input data ready, running an Azure Machine Learning
experiment, and handling the output.</p>
<img alt="../../../_images/mlops.png" class="align-center" src="../../../_images/mlops.png" />
<p>All of this and more in <a class="reference external" href="https://www.manning.com/books/azure-data-engineering">Data Engineering on Azure</a>.</p>
</div>
</div>

    <div class="postmeta">
        
        
        
        </div><ul class="related clearfix">
            <li class="left"></li>
            <li class="right"><a href="../17/machine-learning-on-azure-part-2.html">Machine Learning on Azure - Part 2</a> &raquo; </li>
        </ul></article></div> <!-- #main --></div> <!-- #main-container -->

        <div class="footer-container" role="contentinfo"><div style="text-align: center; color: #93a4ad">
    By Vlad Rișcuția | <a href="http://feeds.feedburner.com/vladris">Subscribe</a> | <a href="http://vladris.com/blog/archive">Archive</a>
</div></div> <!-- footer-container -->

      </div> <!--! end of #container --><!--[if lt IE 7 ]>
          <script src="//ajax.googleapis.com/ajax/libs/chrome-frame/1.0.3/CFInstall.min.js"></script>
          <script>window.attachEvent('onload',function(){CFInstall.check({mode:'overlay'})})</script>
        <![endif]-->
    </body>
</html>