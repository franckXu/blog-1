<!DOCTYPE html><!--[if lt IE 7]>      <html xmlns="http://www.w3.org/1999/xhtml"
    xmlns:og="http://ogp.me/ns#"
    xmlns:fb="https://www.facebook.com/2008/fbml" class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]-->
<!--[if IE 7]>         <html xmlns="http://www.w3.org/1999/xhtml"
    xmlns:og="http://ogp.me/ns#"
    xmlns:fb="https://www.facebook.com/2008/fbml" class="no-js lt-ie9 lt-ie8"> <![endif]-->
<!--[if IE 8]>         <html xmlns="http://www.w3.org/1999/xhtml"
    xmlns:og="http://ogp.me/ns#"
    xmlns:fb="https://www.facebook.com/2008/fbml" class="no-js lt-ie9"> <![endif]-->
<!--[if gt IE 8]><!--> <html xmlns="http://www.w3.org/1999/xhtml"
    xmlns:og="http://ogp.me/ns#"
    xmlns:fb="https://www.facebook.com/2008/fbml" class="no-js"> <!--<![endif]-->
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
        <meta name="description" content="Vlad's Tech Blog">
        <meta name="viewport" content="width=device-width">
        <title>Notes on Data Engineering &mdash; Blog</title>
            <link rel="stylesheet" href="../../../_static/normalize.css" type="text/css">
            <link rel="stylesheet" href="../../../_static/sphinx.css" type="text/css">
            <link rel="stylesheet" href="../../../_static/main.css" type="text/css">
            <link rel="stylesheet" href="../../../_static/flat.css" type="text/css">
            <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
            <link rel="stylesheet" href="../../../_static/font-awesome.min.css" type="text/css">
        <link rel="shortcut icon" href="../../../_static/tinkerer.ico" /><!-- Load modernizr and JQuery -->
        <script src="../../../_static/vendor/modernizr-2.6.2.min.js"></script>
        <script src="//ajax.googleapis.com/ajax/libs/jquery/1.8.2/jquery.min.js"></script>
        <script>window.jQuery || document.write('<script src="../../../_static/vendor/jquery-1.8.2.min.js"><\/script>')</script>
        <script src="../../../_static/plugins.js"></script>
        <script src="../../../_static/main.js"></script>
        <link rel="search" title="Search" href="../../../search.html" /><link rel="next" title="Unit Testing 101" href="../../11/18/unit-testing-101.html" /><link rel="prev" title="Variance" href="../27/variance.html" /><link rel="alternate" type="application/rss+xml" title="RSS" href="../../../rss.html" /><script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../../',
        VERSION:     '1.7.2',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        SOURCELINK_SUFFIX: '.txt',
        HAS_SOURCE:  true
      };
    </script><script type="text/javascript" src="../../../_static/underscore.js"></script><script type="text/javascript" src="../../../_static/doctools.js"></script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type="text/javascript" src="../../../_static/google_analytics.js"></script><link rel="stylesheet" href="../../../_static/extra.css" type="text/css" />
<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
</script></head>
    <body role="document">
        <!--[if lt IE 7]>
            <p class="chromeframe">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> or <a href="http://www.google.com/chromeframe/?redirect=true">activate Google Chrome Frame</a> to improve your experience.</p>
        <![endif]-->

      <div id="container"><div class="main-container" role="main"><div class="main wrapper body clearfix"><article><div class="timestamp postmeta">
            <span>December 08, 2019</span>
        </div>
    <div class="section" id="notes-on-data-engineering">
<h1>Notes on Data Engineering</h1>
<p>For over a year now I’ve been the architect for the Customer Growth and
Analytics team in Azure, scaling out our big data platform as our team grows
and matures. I’m going to share a few observations on some of the main
problems we’ve been solving, problems which I believe are fairly universal: I
attended the <a class="reference external" href="https://conferences.oreilly.com/strata-data-ai">Strata Data Conference</a>
this year and speakers from many other companies were talking about similar
problems and the solutions they were implementing.</p>
<p>Not too long ago, the major challanges were around storing and processing data
at scale. Since this has been more or less commoditized in the past few years,
especially with the emergence of cloud providers, it’s interesting to think
about how the big data landscape evolved and what are some of the present
challenges. I list some of them below.</p>
<div class="section" id="compliance">
<h2>Compliance</h2>
<p>Proper handling of data assets is a top priority for Microsoft and should be
for everyone. There are several aspects I consider to be part of compliance.</p>
<p>First, there are regulatory obligations, probably the best-known example
being GDPR. In order to be compliant with GDPR, a data platform needs to have
the ability to “forget” about a user if the user so desires. A data platform
needs to support all capabilities required by regulations of the countries it
gets its data from. There are many other regulations, and new ones can come
up at any time. Staying compliant is maybe the most important work for a data
platform.</p>
<p>Next, there is access control: who gets to see what data. There are various
types of data for which access should be restricted. Personally Identifiable
Information (PII) is data that can be used to identify a particular person,
like name or email address. High Business Impact (HBI) is data relevant to
the business, like revenue numbers, devices sold etc. Different companies use
different taxonomies to classifies their data assets, but regardless, in the
big data space, it is a non trivial problem to ensure that only people who
are allowed to access a certain data set are able to do so. If access to
sensitive data sets is under a need-to-know basis, and we create one security
group per dataset, just managing those security groups is hard in itself. On
top of that, people move and organizations change and that can impact who has
access to the data too.</p>
<p>I believe there is a lot of room to improve and innovate in this space. There
are many existing solutions to handle both regulatory and access control
requirements, but nothing that feels like <em>it just works</em>, and definitely
little in terms of industry standards.</p>
</div>
<div class="section" id="metadata">
<h2>Metadata</h2>
<p>As the data volume grows, organizing it becomes a big challenge. There is a
need for an additional layer of data about the data, or metadata. There are
several very important pieces of information which are not readily available
in the data itself that a big data platform must provide.</p>
<p>First, there is simply the descriptions of various datasets: what the various
columns are, how often is the data refreshed, how fresh the data is etc.
There also needs to be an ability to search this metadata in order to find
relevant data available in the system.</p>
<p>Next, there is data lineage. Where did the data come from and how was it
sourced? This has compliance implications: for example if end users agree to
share telemetry data for the purpose of improving the product, that data
should not be used for other purposes.</p>
<p>Also for compliance purposes, various datasets and columns have to be tagged
as containing PII or other sensitive information so the system can
automatically lock down or purge this type of sensitive data when needed.</p>
<p>Organizing data at scale also requires some amount of information
architecture. One aspect of this is controlled taxonomies: clear definitions
of what various business terms and data pieces mean, so everyone working in
the space shares the same understanding.</p>
<p><a class="reference external" href="https://azure.microsoft.com/en-us/services/data-catalog/">Azure Data Catalog</a>
is the Azure offering in this space.</p>
</div>
<div class="section" id="heterogeneity-by-design">
<h2>Heterogeneity by Design</h2>
<p>There is no one-size-fits-all data fabric. Each storage solution has some
workflows it was optimized for and some it’s not so great at. It’s next to
impossible to say that absolutely everything will be running on one single
solution, be that SQL, NoSQL, HDFS, or something else. Some workflows need
massive scale (processing terabytes of data), some workflows need fast reads
(serving a website). Teams upstream will expose data from different storage
solutions while teams downstream will expect it in different storage
solutions…</p>
<p>Standardizing on a unique storage solution is unfeasible, so the next best
thing to do is to standardize on the tooling to move the data around and
ensure that it is easy to operate: make it easy to create a new data movement
pipeline, provide monitoring, alerting etc. Since data movement is a
necessity, it must be as reliable as possible.</p>
<p>Our team uses <a class="reference external" href="https://azure.microsoft.com/en-us/services/data-factory/">Azure Data Factory</a>
for orchestrating data movement at scale.</p>
</div>
<div class="section" id="devops">
<h2>DevOps</h2>
<p>Another major bucket of work is bringing engineering rigor to workflows
supported by other disciplines like data science and machine learning
engineering. Again, with a small team, it is relatively easy to create ad-hoc
reports and run ad-hoc ML but this approach doesn’t scale. Once production
systems depend on the output.</p>
<p>This is a solved problem in the software engineering field: source control,
code reviews, continuous integration and so on. But non-engineering
disciplines are not accustomed to this type of workflow so there is
definitely a need to educate, support, and create similar devops workflows.
Analytics and ML ultimately reduce to code (SQL queries, Python, R etc.) and
should be handled just as production code.</p>
<p>Our team supports these types of workflows using <a class="reference external" href="https://azure.microsoft.com/en-us/services/devops/">Azure DevOps</a>
with pipelines that can deploy ML and analytics from git to our production
environment.</p>
</div>
<div class="section" id="data-quality">
<h2>Data Quality</h2>
<p>The last topic I will cover is data quality. The quality of all analytics and
machine learning outputs depends on the quality of the underlying data.</p>
<p>There are multiple aspects to data quality. One set of definitions is given
by the article <a class="reference external" href="https://smartbridge.com/data-done-right-6-dimensions-of-data-quality/">Data Done Right: 6 Dimensions of Data Quality</a>:</p>
<ul class="simple">
<li>Completeness - the dataset is not missing any required data</li>
<li>Consistency - the data is consistent across multiple datasets</li>
<li>Conformity - all data in the right format, within the right value ranges etc.</li>
<li>Accuracy - the data accurately represents the domain being modelled</li>
<li>Integrity - the data is valid across all relationships and datasets</li>
<li>Timeliness - the data available when expected and datasets are not delayed</li>
</ul>
<p>A reliable data platform can run various types of data quality tests on
the managed datasets, both at scheduled times and during ingress. Issues have
to be reported and the overall state of the data quality made visible through
a dashboard so stakeholders can easily see which datasets currently have
problems and what are the potential implications of that.</p>
<p>As of today, this seems to be a big gap in terms of industry-wide standard
solutions. Data engineering teams develop their bespoke data test runners for
their scenarios. There are many open source solutions, but we don’t have the
equivalent of JUnit yet, nor a common language for specifying tests and
assertions.</p>
</div>
<div class="section" id="conclusions">
<h2>Conclusions</h2>
<p>In the following years, I expect we will have both better tooling for some
of these problems and better defined industry-wide standards. As I mentioned
at the beginning of this post, not long ago, just storing and processing huge
amounts of data was a hard problem. Today, the main challanges are around
organizing and managing data. I fully expect that in the near future we will
have out-of-the-box solutions for all these problems and a new set of
challanges will emerge.</p>
</div>
</div>

    <div class="postmeta">
        
        
        
        </div><ul class="related clearfix">
            <li class="left"> &laquo; <a href="../27/variance.html">Variance</a></li>
            <li class="right"><a href="../../11/18/unit-testing-101.html">Unit Testing 101</a> &raquo; </li>
        </ul></article></div> <!-- #main --></div> <!-- #main-container -->

        <div class="footer-container" role="contentinfo"><div style="text-align: center; color: #93a4ad">
    By Vlad Rișcuția | <a href="http://feeds.feedburner.com/vladris">Subscribe</a> | <a href="http://vladris.com/blog/archive">Archive</a>
</div></div> <!-- footer-container -->

      </div> <!--! end of #container --><!--[if lt IE 7 ]>
          <script src="//ajax.googleapis.com/ajax/libs/chrome-frame/1.0.3/CFInstall.min.js"></script>
          <script>window.attachEvent('onload',function(){CFInstall.check({mode:'overlay'})})</script>
        <![endif]-->
    </body>
</html>